{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(10)[[0, 1, 2, 3, 4, 5, 6, 7, 8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([100, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(root='D:/work/data/Python/mnist/', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='D:/work/data/Python/mnist/', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron():\n",
    "\n",
    "    def __init__(self, num_features, num_hidden, num_classes):\n",
    "        super(MultilayerPerceptron, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # hidden 1\n",
    "        self.weight_1 = torch.zeros(num_hidden, num_features, \n",
    "                                    dtype=torch.float).normal_(0.0, 0.1)\n",
    "        self.bias_1 = torch.zeros(num_hidden, dtype=torch.float)\n",
    "        \n",
    "        # output\n",
    "        self.weight_o = torch.zeros(self.num_classes, num_hidden, \n",
    "                                    dtype=torch.float).normal_(0.0, 0.1)\n",
    "        self.bias_o = torch.zeros(self.num_classes, dtype=torch.float)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # hidden 1\n",
    "        \n",
    "        # input dim: [n_hidden, n_features] dot [n_features, n_examples] .T\n",
    "        # output dim: [n_examples, n_hidden]\n",
    "        z_1 = torch.mm(x, self.weight_1.t()) + self.bias_1\n",
    "        a_1 = torch.sigmoid(z_1)\n",
    "\n",
    "        # hidden 2\n",
    "        # input dim: [n_classes, n_hidden] dot [n_hidden, n_examples] .T\n",
    "        # output dim: [n_examples, n_classes]\n",
    "        z_2 = torch.mm(a_1, self.weight_o.t()) + self.bias_o\n",
    "        a_2 = torch.sigmoid(z_2)\n",
    "        return a_1, a_2\n",
    "\n",
    "    def backward(self, x, a_1, a_2, y):\n",
    "        '''\n",
    "            sigmoid'(Z2)表示simoid函数对Z2求导, a2 = sigmoid(Z2), sigmoid'(Z2) = a2*(1 - a2)\n",
    "            \n",
    "            dZ2 = (a2 - y) @ sigmoid'(Z2)\n",
    "            dW2 = a1 @ dZ2\n",
    "            db1 = dZ2\n",
    "            \n",
    "            dZ1 = W2 @ dZ2 @ sigmoid'(Z1)\n",
    "            dW1 = X @ dZ1\n",
    "            db1 = dZ1\n",
    "        '''\n",
    "        y_onehot = torch.zeros(y.size(0), self.num_classes).scatter_(1, y.view(-1,1).long(), 1)\n",
    "        \n",
    "        '''\n",
    "            a2: [n_examples, n_classes]\n",
    "            dZ2: [n_examples, n_classes]\n",
    "            dw2: [num_classes, num_hidden]\n",
    "            db2: [num_classes]\n",
    "            \n",
    "            a1: [n_examples, num_hidden]\n",
    "            dZ1: [n_examples, num_hidden]\n",
    "            dW1: [num_hidden, num_features]\n",
    "            db1: [num_hidden]\n",
    "        '''\n",
    "#         print(x.size())\n",
    "#         print(a_1.size())\n",
    "#         print(a_2.size())\n",
    "#         print(y.size())\n",
    "#         print(y_onehot.size())\n",
    "        \n",
    "        # sigmoid derivative: da2 / dZ2\n",
    "        da2_dZ2 = a_2 * (1 - a_2)\n",
    "        # Z2 derivative: dLoss / dZ2\n",
    "        # dZ2: [n_examples, n_classes]\n",
    "        dZ2 = (a_2 - y_onehot) * da2_dZ2\n",
    "        # W2 derivative: dLoss / dW2\n",
    "        # dW2: [num_classes, num_hidden]\n",
    "        dW2 = torch.mm(dZ2.t(), a_1)\n",
    "        db2 = torch.sum(dZ2, dim=0)\n",
    "        assert(dW2.size(0) == self.num_classes && dW2.size(1) == self.num_hidden)\n",
    "        \n",
    "        da1_dZ1 = a_1 * (1 - a_1)\n",
    "        # dZ1: [n_examples, num_hidden]\n",
    "        dZ1 = torch.mm(dZ2, self.weight_o.t()) * da1_dZ1\n",
    "        # dW1: [num_hidden, num_features]\n",
    "        dW1 = torch.mm(dZ1.t(), x)\n",
    "        db1 = torch.sum(dZ1, dim=0)\n",
    "        return dloss__dw_out, dloss__db_out, dloss_dw1, dloss_db1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(y, num_classes):\n",
    "    y_onehot = torch.FloatTensor(y.size(0), num_classes)\n",
    "    y_onehot.zero_()\n",
    "    y_onehot.scatter_(1, y.view(-1, 1).long(), 1).float()\n",
    "    return y_onehot\n",
    "\n",
    "\n",
    "def loss_func(targets_onehot, probas_onehot):\n",
    "    return torch.mean(torch.mean((targets_onehot - probas_onehot)**2, dim=0))\n",
    "\n",
    "\n",
    "def compute_mse(net, data_loader):\n",
    "    curr_mse, num_examples = torch.zeros(model.num_classes).float(), 0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.view(-1, 28*28)\n",
    "            logits, probas = net.forward(features)\n",
    "            y_onehot = to_onehot(targets, model.num_classes)\n",
    "            loss = torch.sum((y_onehot - probas)**2, dim=0)\n",
    "            num_examples += targets.size(0)\n",
    "            curr_mse += loss\n",
    "\n",
    "        curr_mse = torch.mean(curr_mse/num_examples, dim=0)\n",
    "        return curr_mse\n",
    "\n",
    "\n",
    "def train(model, data_loader, num_epochs,\n",
    "          learning_rate=0.1):\n",
    "    \n",
    "    minibatch_cost = []\n",
    "    epoch_cost = []\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        \n",
    "        for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "            \n",
    "            features = features.view(-1, 28*28)\n",
    "            \n",
    "            #### Compute outputs ####\n",
    "            a_1, a_2 = model.forward(features)\n",
    "\n",
    "            #### Compute gradients ####\n",
    "            dloss__dw_out, dloss__db_out, dloss_dw1, dloss_db1 = \\\n",
    "                model.backward(features, a_1, a_2, targets)\n",
    "\n",
    "            #### Update weights ####\n",
    "            model.weight_1 -= learning_rate * dloss_dw1\n",
    "            model.bias_1 -= learning_rate * dloss_db1\n",
    "            model.weight_o -= learning_rate * dloss__dw_out\n",
    "            model.bias_o -= learning_rate * dloss__db_out\n",
    "            \n",
    "            #### Logging ####\n",
    "            curr_cost = loss_func(to_onehot(targets, model.num_classes), a_2)\n",
    "            minibatch_cost.append(curr_cost)\n",
    "            if not batch_idx % 50:\n",
    "                print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                       %(e+1, NUM_EPOCHS, batch_idx, \n",
    "                         len(train_loader), curr_cost))\n",
    "        \n",
    "        #### Logging ####        \n",
    "        curr_cost = compute_mse(model, train_loader)\n",
    "        epoch_cost.append(curr_cost)\n",
    "        print('Epoch: %03d/%03d |' % (e+1, NUM_EPOCHS), end=\"\")\n",
    "        print(' Train MSE: %.5f' % curr_cost)\n",
    "\n",
    "    return minibatch_cost, epoch_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784])\n",
      "torch.Size([100, 50])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 10])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (100) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f1d7b3725600>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                    \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                    \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                                    learning_rate=0.1)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-8b8637461cc7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, num_epochs, learning_rate)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m#### Compute gradients ####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mdloss__dw_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdloss__db_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdloss_dw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdloss_db1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;31m#### Update weights ####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-5bfb20cd22eb>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, x, a_1, a_2, y)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mda2_dZ2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma_2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m# Z2 derivative: dLoss / dZ2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mdZ2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma_2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mda2_dZ2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[1;31m# W2 derivative: dLoss / dW2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mdW2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdZ2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (100) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = MultilayerPerceptron(num_features=28*28,\n",
    "                             num_hidden=50,\n",
    "                             num_classes=10)\n",
    "\n",
    "minibatch_cost, epoch_cost = train(model, \n",
    "                                   train_loader,\n",
    "                                   num_epochs=NUM_EPOCHS,\n",
    "                                   learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(minibatch_cost)), minibatch_cost)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Minibatch')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(epoch_cost)), epoch_cost)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(net, data_loader):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.view(-1, 28*28)\n",
    "            _, outputs = net.forward(features)\n",
    "            predicted_labels = torch.argmax(outputs, 1)\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "        return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "print('Training Accuracy: %.2f' % compute_accuracy(model, train_loader))\n",
    "print('Test Accuracy: %.2f' % compute_accuracy(model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for features, targets in test_loader:\n",
    "    break\n",
    "    \n",
    "fig, ax = plt.subplots(1, 4)\n",
    "for i in range(4):\n",
    "    ax[i].imshow(features[i].view(28, 28), cmap=matplotlib.cm.binary)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions = model.forward(features[:4].view(-1, 28*28))\n",
    "predictions = torch.argmax(predictions, dim=1)\n",
    "print('Predicted labels', predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
