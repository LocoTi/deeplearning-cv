{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribute a Model Across Multiple GPUs with Pipeline Parallelism\n",
    "\n",
    "\n",
    "This notebook demos pipeline parallelism added to PyTorch 1.8 using VGG-16 as an example. For more details, see https://pytorch.org/docs/1.8.0/pipeline.html?highlight=pipeline#."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from typing import Union, List, Dict, Any, cast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../..\") # to include ../helper_evaluate.py etc.\n",
    "from helper_utils import set_all_seeds, set_deterministic\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 47\n",
    "learning_rate = 0.0001\n",
    "batch_size = 8\n",
    "epochs = 10\n",
    "\n",
    "num_classes = 5\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "save_path = \"vgg16_flower.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(random_seed)\n",
    "\n",
    "set_deterministic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 0 dataloader workers every process\n",
      "train images num:  3306\n",
      "test images num:  364\n",
      "images shape:  torch.Size([8, 3, 32, 32])\n",
      "labels shape:  torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(32),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "test_transform = transforms.Compose([transforms.RandomResizedCrop((32, 32)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "image_path = \"D:/work/data/Python/flower_data/\"\n",
    "assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"), transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"), transform=test_transform)\n",
    "\n",
    "flower_list = train_dataset.class_to_idx\n",
    "class_dict = dict((val, key) for key, val in flower_list.items())\n",
    "\n",
    "# dump dict too json file\n",
    "json_str = json.dumps(class_dict, indent=4)\n",
    "with open(\"class_indices.json\", \"w\") as json_file:\n",
    "    json_file.write(json_str)\n",
    "#     json.dump(class_dict, json_file, ensure_ascii=False)\n",
    "\n",
    "num_workers = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 0])\n",
    "print('Using {} dataloader workers every process'.format(num_workers))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "train_num = len(train_dataset)\n",
    "test_num = len(test_dataset)\n",
    "\n",
    "print(\"train images num: \", train_num)\n",
    "print(\"test images num: \", test_num)\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(\"images shape: \", images.size())\n",
    "    print(\"labels shape: \", labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 8\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 8\n",
      "Epoch: 3 | Batch index: 0 | Batch size: 8\n",
      "Epoch: 4 | Batch index: 0 | Batch size: 8\n",
      "Epoch: 5 | Batch index: 0 | Batch size: 8\n",
      "Epoch: 6 | Batch index: 0 | Batch size: 8\n",
      "Epoch: 7 | Batch index: 0 | Batch size: 8\n",
      "Epoch: 8 | Batch index: 0 | Batch size: 8\n",
      "Epoch: 9 | Batch index: 0 | Batch size: 8\n",
      "Epoch: 10 | Batch index: 0 | Batch size: 8\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # calculate same padding:\n",
    "        # (w - k + 2*p)/s + 1 = o\n",
    "        # => p = (s(o-1) - w + k)/2\n",
    "        \n",
    "        self.block_1 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=3,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          # (1(32-1)- 32 + 3)/2 = 1\n",
    "                          padding=1), \n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(in_channels=64,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_2 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=64,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(in_channels=128,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_3 = torch.nn.Sequential(        \n",
    "                torch.nn.Conv2d(in_channels=128,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(in_channels=256,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                torch.nn.ReLU(),        \n",
    "                torch.nn.Conv2d(in_channels=256,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "          \n",
    "        self.block_4 = torch.nn.Sequential(   \n",
    "                torch.nn.Conv2d(in_channels=256,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                torch.nn.ReLU(),        \n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                torch.nn.ReLU(),        \n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                torch.nn.ReLU(),            \n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_5 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                torch.nn.ReLU(),            \n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                torch.nn.ReLU(),            \n",
    "                torch.nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                torch.nn.ReLU(),    \n",
    "                torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))             \n",
    "        )\n",
    "            \n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(512, 4096),\n",
    "            torch.nn.ReLU(True),\n",
    "            #torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(4096, 4096),\n",
    "            torch.nn.ReLU(True),\n",
    "            #torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.block_4(x)\n",
    "        x = self.block_5(x)\n",
    "        x = self.classifier(x) # logits\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = VGG16(num_classes=num_classes)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Regular (1-GPU) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[1/10] loss:1.733: 100%|██████████████████████████████████████████████████| 414/414 [01:41<00:00,  4.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:06<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 1.604  val_accuracy: 0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[2/10] loss:1.808:   0%|▏                                                   | 1/414 [00:00<00:49,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model pth to vgg16_flower.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[2/10] loss:1.090: 100%|██████████████████████████████████████████████████| 414/414 [00:48<00:00,  8.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train_loss: 1.504  val_accuracy: 0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[3/10] loss:1.493:   0%|▏                                                   | 1/414 [00:00<00:45,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model pth to vgg16_flower.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[3/10] loss:1.736: 100%|██████████████████████████████████████████████████| 414/414 [00:49<00:00,  8.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 25.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] train_loss: 1.311  val_accuracy: 0.415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[4/10] loss:1.110:   0%|▏                                                   | 1/414 [00:00<00:48,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model pth to vgg16_flower.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[4/10] loss:0.821: 100%|██████████████████████████████████████████████████| 414/414 [00:51<00:00,  8.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 26.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] train_loss: 1.259  val_accuracy: 0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/414 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model pth to vgg16_flower.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[5/10] loss:1.611: 100%|██████████████████████████████████████████████████| 414/414 [00:50<00:00,  8.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 25.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] train_loss: 1.243  val_accuracy: 0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[6/10] loss:1.010:   0%|▏                                                   | 1/414 [00:00<00:41,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model pth to vgg16_flower.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[6/10] loss:0.736: 100%|██████████████████████████████████████████████████| 414/414 [00:51<00:00,  8.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 24.79it/s]\n",
      "train epoch[7/10] loss:1.179:   0%|▏                                                   | 1/414 [00:00<00:47,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] train_loss: 1.206  val_accuracy: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[7/10] loss:0.994: 100%|██████████████████████████████████████████████████| 414/414 [00:51<00:00,  8.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 25.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] train_loss: 1.184  val_accuracy: 0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[8/10] loss:0.883:   0%|▏                                                   | 1/414 [00:00<00:52,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model pth to vgg16_flower.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[8/10] loss:0.935: 100%|██████████████████████████████████████████████████| 414/414 [00:51<00:00,  8.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 23.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] train_loss: 1.148  val_accuracy: 0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[9/10] loss:1.033:   0%|▏                                                   | 1/414 [00:00<00:50,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model pth to vgg16_flower.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[9/10] loss:1.333: 100%|██████████████████████████████████████████████████| 414/414 [00:53<00:00,  7.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 25.48it/s]\n",
      "train epoch[10/10] loss:0.887:   0%|                                                   | 1/414 [00:00<00:49,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] train_loss: 1.106  val_accuracy: 0.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[10/10] loss:0.379: 100%|█████████████████████████████████████████████████| 414/414 [00:52<00:00,  7.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:01<00:00, 24.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] train_loss: 1.118  val_accuracy: 0.607\n",
      "save model pth to vgg16_flower.pth\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "# train_steps: train_num // batch_size\n",
    "train_steps = len(train_loader)\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_loader)\n",
    "    running_loss = 0.0\n",
    "    for step, (images, labels) in enumerate(train_bar):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        logits = model(images)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # logging\n",
    "        running_loss += loss.item()\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1, epochs, loss)\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(test_loader)\n",
    "        for images, labels in test_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            logits = model(images)\n",
    "            _, predict_labels = torch.max(logits, dim=1)\n",
    "            correct += torch.eq(predict_labels, labels).sum().float()\n",
    "    \n",
    "    test_acc = correct / test_num\n",
    "    train_loss = running_loss / train_steps\n",
    "    print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, train_loss, test_acc))\n",
    "    \n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\"save model pth to %s\" % (save_path))\n",
    "    \n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) VGG16 with Pipeline Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_1 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channels=3,\n",
    "                  out_channels=64,\n",
    "                  kernel_size=(3, 3),\n",
    "                  stride=(1, 1),\n",
    "                  # (1(32-1)- 32 + 3)/2 = 1\n",
    "                  padding=1), \n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(in_channels=64,\n",
    "                  out_channels=64,\n",
    "                  kernel_size=(3, 3),\n",
    "                  stride=(1, 1),\n",
    "                  padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                     stride=(2, 2))\n",
    ")\n",
    "\n",
    "block_2 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channels=64,\n",
    "                  out_channels=128,\n",
    "                  kernel_size=(3, 3),\n",
    "                  stride=(1, 1),\n",
    "                  padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(in_channels=128,\n",
    "                  out_channels=128,\n",
    "                  kernel_size=(3, 3),\n",
    "                  stride=(1, 1),\n",
    "                  padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                     stride=(2, 2))\n",
    ")\n",
    "        \n",
    "block_3 = torch.nn.Sequential(        \n",
    "        torch.nn.Conv2d(in_channels=128,\n",
    "                  out_channels=256,\n",
    "                  kernel_size=(3, 3),\n",
    "                  stride=(1, 1),\n",
    "                  padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(in_channels=256,\n",
    "                  out_channels=256,\n",
    "                  kernel_size=(3, 3),\n",
    "                  stride=(1, 1),\n",
    "                  padding=1),\n",
    "        torch.nn.ReLU(),        \n",
    "        torch.nn.Conv2d(in_channels=256,\n",
    "                  out_channels=256,\n",
    "                  kernel_size=(3, 3),\n",
    "                  stride=(1, 1),\n",
    "                  padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                     stride=(2, 2))\n",
    ")\n",
    "        \n",
    "          \n",
    "block_4 = torch.nn.Sequential(   \n",
    "        torch.nn.Conv2d(in_channels=256,\n",
    "                  out_channels=512,\n",
    "                  kernel_size=(3, 3),\n",
    "                  stride=(1, 1),\n",
    "                  padding=1),\n",
    "        torch.nn.ReLU(),        \n",
    "        torch.nn.Conv2d(in_channels=512,\n",
    "                  out_channels=512,\n",
    "                  kernel_size=(3, 3),\n",
    "                  stride=(1, 1),\n",
    "                  padding=1),\n",
    "        torch.nn.ReLU(),        \n",
    "        torch.nn.Conv2d(in_channels=512,\n",
    "                  out_channels=512,\n",
    "                  kernel_size=(3, 3),\n",
    "                  stride=(1, 1),\n",
    "                  padding=1),\n",
    "        torch.nn.ReLU(),            \n",
    "        torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                     stride=(2, 2))\n",
    ")\n",
    "        \n",
    "block_5 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channels=512,\n",
    "                  out_channels=512,\n",
    "                  kernel_size=(3, 3),\n",
    "                  stride=(1, 1),\n",
    "                  padding=1),\n",
    "        torch.nn.ReLU(),            \n",
    "        torch.nn.Conv2d(in_channels=512,\n",
    "                  out_channels=512,\n",
    "                  kernel_size=(3, 3),\n",
    "                  stride=(1, 1),\n",
    "                  padding=1),\n",
    "        torch.nn.ReLU(),            \n",
    "        torch.nn.Conv2d(in_channels=512,\n",
    "                  out_channels=512,\n",
    "                  kernel_size=(3, 3),\n",
    "                  stride=(1, 1),\n",
    "                  padding=1),\n",
    "        torch.nn.ReLU(),    \n",
    "        torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                     stride=(2, 2))             \n",
    ")\n",
    "            \n",
    "classifier = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(512, 4096),\n",
    "    torch.nn.ReLU(True),\n",
    "    #torch.nn.Dropout(p=0.5),\n",
    "    torch.nn.Linear(4096, 4096),\n",
    "    torch.nn.ReLU(True),\n",
    "    #torch.nn.Dropout(p=0.5),\n",
    "    torch.nn.Linear(4096, num_classes),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributed.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MASTER_ADDR=xxx.xx.xx.xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MASTER_PORT=8891"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the RPC if it is not already running (more details at https://pytorch.org/docs/stable/rpc.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    torch.distributed.rpc.init_rpc(name='node1', rank=0, world_size=1)\n",
    "except RuntimeError as e:\n",
    "    if str(e) == 'Address already in use':\n",
    "        pass\n",
    "    else:\n",
    "        raise RuntimeError(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main part for running the model on multiple GPUs.\n",
    "\n",
    "1. We wrap the individual blocks into a Sequential model\n",
    "2. The chunks refer to the microbatches, for more details, see https://pytorch.org/docs/1.8.0/pipeline.html?highlight=pipeline#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributed.pipeline.sync import Pipe\n",
    "\n",
    "\n",
    "block1 = block_1.cuda(0)\n",
    "block2 = block_2.cuda(0)\n",
    "block3 = block_3.cuda(2)\n",
    "block4 = block_4.cuda(2)\n",
    "block4 = block_5.cuda(3)\n",
    "block4 = classifier.cuda(0)\n",
    "\n",
    "model_parallel = torch.nn.Sequential(\n",
    "    block_1, block_2, block_3, block_4, block_5, classifier)\n",
    "model_parallel = Pipe(model_parallel, chunks=8)\n",
    "optimizer = torch.optim.Adam(model_parallel.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "print(device)\n",
    "\n",
    "best_acc = 0.0\n",
    "# train_steps: train_num // batch_size\n",
    "train_steps = len(train_loader)\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_loader)\n",
    "    running_loss = 0.0\n",
    "    for step, (images, labels) in enumerate(train_bar):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        logits = model_parallel(images)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # logging\n",
    "        running_loss += loss.item()\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1, epochs, loss)\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(test_loader)\n",
    "        for images, labels in test_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            logits = model(images)\n",
    "            _, predict_labels = torch.max(logits, dim=1)\n",
    "            correct += torch.eq(predict_labels, labels).sum().float()\n",
    "    \n",
    "    test_acc = correct / test_num\n",
    "    train_loss = running_loss / train_steps\n",
    "    print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, train_loss, test_acc))\n",
    "    \n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\"save model pth to %s\" % (save_path))\n",
    "    \n",
    "print(\"Finished training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
