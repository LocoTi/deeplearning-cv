{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorFlow's Dataset API\n",
    "\n",
    "TensorFlow provides users with multiple options for providing data to the model. One of the probably most common methods is to define placeholders in the TensorFlow graph and feed the data from the current Python session into the TensorFlow Session using the feed_dict parameter. Using this approach, a large dataset that does not fit into memory is most conveniently and efficiently stored using NumPy archives as explained in [Chunking an Image Dataset for Minibatch Training using NumPy NPZ Archives](https://render.githubusercontent.com/view/image-data-chunking-npz.ipynb) or HDF5 data base files ([Storing an Image Dataset for Minibatch Training using HDF5](https://render.githubusercontent.com/view/image-data-chunking-hdf5.ipynb)).\n",
    "\n",
    "Another approach, which is often preferred when it comes to computational efficiency, is to do the \"data loading\" directly in the graph using input queues from so-called TFRecords files, which is illustrated in the [Using Input Pipelines to Read Data from TFRecords Files](https://render.githubusercontent.com/view/tfrecords.ipynb) notebook.\n",
    "\n",
    "Now, one could also use inpute input queues to load the data directly on the graph [Using Queue Runners to Feed Images Directly from Disk](https://render.githubusercontent.com/view/file-queues.ipynb). The examples in this Jupyter notebook present an alternative to this manual approach, using TensorFlow's \"new\" Dataset API, which is described in more detail here: https://www.tensorflow.org/programmers_guide/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from helper import mnist_export_to_jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/work/data/Python/tensorflow/mnist/data/\n",
      "WARNING:tensorflow:From ..\\helper.py:183: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\AdvanceIDE\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\AdvanceIDE\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting D:/work/data/Python/tensorflow/mnist/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\AdvanceIDE\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting D:/work/data/Python/tensorflow/mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting D:/work/data/Python/tensorflow/mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting D:/work/data/Python/tensorflow/mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\AdvanceIDE\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "55000\n"
     ]
    }
   ],
   "source": [
    "random_seed = 123\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "mnist_path = \"D:/work/data/Python/tensorflow/mnist/data/\"\n",
    "mnist_export_to_jpg(path=mnist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_train subdirectories ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "mnist_valid subdirectories ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "mnist_test subdirectories ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for i in ('train', 'valid', 'test'):\n",
    "    print('mnist_%s subdirectories' % i, os.listdir(os.path.join(mnist_path, 'mnist_%s' % i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "mnist_train_path = os.path.join(mnist_path, 'mnist_train/9/')\n",
    "some_img = os.path.join(mnist_train_path, os.listdir(mnist_train_path)[0])\n",
    "\n",
    "img = mpimg.imread(some_img)\n",
    "print(img.shape)\n",
    "plt.imshow(img, cmap='binary');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import re\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "train_paths = glob.glob(mnist_path + 'mnist_train/**/*.jpg', recursive=True)\n",
    "train_labels = [int(re.split(\"/|\\\\\\\\\", s)[-2]) for s in train_paths]\n",
    "tmp = list(zip(train_paths, train_labels))\n",
    "random.shuffle(tmp)\n",
    "train_paths, train_labels = zip(*tmp)\n",
    "\n",
    "valid_paths = glob.glob(mnist_path + 'mnist_valid/**/*.jpg', recursive=True)\n",
    "valid_labels = [int(re.split(\"/|\\\\\\\\\", s)[-2]) for s in valid_paths]\n",
    "tmp = list(zip(valid_paths, valid_labels))\n",
    "random.shuffle(tmp)\n",
    "valid_paths, valid_labels = zip(*tmp)\n",
    "\n",
    "test_paths = glob.glob(mnist_path + 'mnist_test/**/*.jpg', recursive=True)\n",
    "test_labels = [int(re.split(\"/|\\\\\\\\\", s)[-2]) for s in test_paths]\n",
    "tmp = list(zip(test_paths, test_labels))\n",
    "random.shuffle(tmp)\n",
    "test_paths, test_labels = zip(*tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-9733ae4c860b>:28: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "WARNING:tensorflow:From <ipython-input-31-9733ae4c860b>:29: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "WARNING:tensorflow:From D:\\AdvanceIDE\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "WARNING:tensorflow:From D:\\AdvanceIDE\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "WARNING:tensorflow:From D:\\AdvanceIDE\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "data_g1 = tf.Graph()\n",
    "\n",
    "with data_g1.as_default():\n",
    "    \n",
    "    # setup tensor elements for the dataset\n",
    "    tf_train_paths = tf.constant(train_paths)\n",
    "    tf_train_labels = tf.constant(train_labels)\n",
    "    tf_valid_paths = tf.constant(valid_paths)\n",
    "    tf_valid_labels = tf.constant(valid_labels)\n",
    "    tf_test_paths = tf.constant(test_paths)\n",
    "    tf_test_labels = tf.constant(test_labels)\n",
    "    \n",
    "    \n",
    "    # construct datasets from tf.Tensor objects\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((tf_train_paths,\n",
    "                                                        tf_train_labels)) \n",
    "    valid_dataset = tf.data.Dataset.from_tensor_slices((tf_valid_paths,\n",
    "                                                        tf_valid_labels)) \n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((tf_test_paths,\n",
    "                                                       tf_test_labels)) \n",
    "    \n",
    "    # initializing iterator to extract elements from the dataset\n",
    "    #   Note: only need 1 iterator, since validation and test \n",
    "    #   datasets have the same image shapes\n",
    "    iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "    \n",
    "    # define op that fetches the next element from the iterator\n",
    "    next_element = iterator.get_next()\n",
    "    \n",
    "    # define initializers for the iterator\n",
    "    train_iter_init = iterator.make_initializer(train_dataset)\n",
    "    valid_iter_init = iterator.make_initializer(valid_dataset)\n",
    "    test_iter_init = iterator.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetch element #1 from training dataset:\n",
      "(b'D:/work/data/Python/tensorflow/mnist/data/mnist_train\\\\5\\\\03475.jpg', 5)\n",
      "Fetch element #2 from training dataset:\n",
      "(b'D:/work/data/Python/tensorflow/mnist/data/mnist_train\\\\2\\\\35329.jpg', 2)\n",
      "Fetch element #3 from training dataset:\n",
      "(b'D:/work/data/Python/tensorflow/mnist/data/mnist_train\\\\8\\\\40264.jpg', 8)\n",
      "\n",
      "Fetch element #1 from validation dataset:\n",
      "(b'D:/work/data/Python/tensorflow/mnist/data/mnist_valid\\\\0\\\\45967.jpg', 0)\n",
      "Fetch element #2 from validation dataset:\n",
      "(b'D:/work/data/Python/tensorflow/mnist/data/mnist_valid\\\\6\\\\45182.jpg', 6)\n",
      "Fetch element #3 from validation dataset:\n",
      "(b'D:/work/data/Python/tensorflow/mnist/data/mnist_valid\\\\7\\\\46306.jpg', 7)\n",
      "\n",
      "Fetch element #1 from test dataset:\n",
      "(b'D:/work/data/Python/tensorflow/mnist/data/mnist_test\\\\2\\\\04656.jpg', 2)\n",
      "Fetch element #2 from test dataset:\n",
      "(b'D:/work/data/Python/tensorflow/mnist/data/mnist_test\\\\9\\\\06109.jpg', 9)\n",
      "Fetch element #3 from test dataset:\n",
      "(b'D:/work/data/Python/tensorflow/mnist/data/mnist_test\\\\5\\\\01958.jpg', 5)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=data_g1) as sess:\n",
    "\n",
    "    sess.run(train_iter_init)\n",
    "    for i in range(3):\n",
    "        print('Fetch element #%d from training dataset:' % (i+1))\n",
    "        ele = sess.run(next_element)\n",
    "        print(ele)\n",
    "    \n",
    "    print()\n",
    "    sess.run(valid_iter_init)\n",
    "    for i in range(3):\n",
    "        print('Fetch element #%d from validation dataset:' % (i+1))\n",
    "        ele = sess.run(next_element)\n",
    "        print(ele)\n",
    "        \n",
    "    print()\n",
    "    sess.run(test_iter_init)\n",
    "    for i in range(3):\n",
    "        print('Fetch element #%d from test dataset:' % (i+1))\n",
    "        ele = sess.run(next_element)\n",
    "        print(ele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_jpg_onehot(path, label):\n",
    "    str_tensor = tf.read_file(path)\n",
    "    decoded_image = tf.image.decode_jpeg(str_tensor,\n",
    "                                         channels=1,\n",
    "                                         fancy_upscaling=False)\n",
    "    # normalize to [0, 1] range\n",
    "    decoded_image = tf.cast(decoded_image, tf.float32)\n",
    "    decoded_image = decoded_image / 255.\n",
    "    # depth=10 because we have 10 mnist class labels\n",
    "    onehot_label = tf.one_hot(label, depth=10)\n",
    "    return decoded_image, onehot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\AdvanceIDE\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow_core\\python\\autograph\\converters\\directives.py:119: The name tf.read_file is deprecated. Please use tf.io.read_file instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def datareader():\n",
    "    tf_train_paths = tf.constant(train_paths)\n",
    "    tf_train_labels = tf.constant(train_labels)\n",
    "    tf_valid_paths = tf.constant(valid_paths)\n",
    "    tf_valid_labels = tf.constant(valid_labels)\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((tf_train_paths,\n",
    "                                                        tf_train_labels)) \n",
    "    valid_dataset = tf.data.Dataset.from_tensor_slices((tf_valid_paths,\n",
    "                                                        tf_valid_labels)) \n",
    "    \n",
    "    ############################################################\n",
    "    ## Custom data transformation; \n",
    "    #  here: image reading, shuffling, batching\n",
    "    train_dataset = train_dataset.map(read_image_jpg_onehot,\n",
    "                                      num_parallel_calls=4)\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1000)\n",
    "    train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    valid_dataset = valid_dataset.map(read_image_jpg_onehot,\n",
    "                                      num_parallel_calls=4)\n",
    "    valid_dataset = valid_dataset.batch(BATCH_SIZE)\n",
    "    ############################################################\n",
    "\n",
    "    iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "\n",
    "    next_element = iterator.get_next(name='next_element')\n",
    "    \n",
    "    train_iter_init = iterator.make_initializer(train_dataset,\n",
    "                                                name='train_iter_init')\n",
    "    valid_iter_init = iterator.make_initializer(valid_dataset,\n",
    "                                                name='valid_iter_init')\n",
    "    \n",
    "    return next_element\n",
    "\n",
    "\n",
    "data_g2 = tf.Graph()\n",
    "with data_g2.as_default():\n",
    "    datareader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetch batch #1 from training dataset:\n",
      "(128, 28, 28, 1) (128, 10)\n",
      "Fetch batch #2 from training dataset:\n",
      "(128, 28, 28, 1) (128, 10)\n",
      "Fetch batch #3 from training dataset:\n",
      "(128, 28, 28, 1) (128, 10)\n",
      "\n",
      "Fetch batch #1 from validation dataset:\n",
      "(128, 28, 28, 1) (128, 10)\n",
      "Fetch batch #2 from validation dataset:\n",
      "(128, 28, 28, 1) (128, 10)\n",
      "Fetch batch #3 from validation dataset:\n",
      "(128, 28, 28, 1) (128, 10)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=data_g2) as sess:\n",
    "\n",
    "    sess.run('train_iter_init')\n",
    "    for i in range(3):\n",
    "        print('Fetch batch #%d from training dataset:' % (i+1))\n",
    "        images, labels = sess.run(['next_element:0', 'next_element:1'])\n",
    "        print(images.shape, labels.shape)\n",
    "        \n",
    "    print()\n",
    "    sess.run('valid_iter_init')\n",
    "    for i in range(3):\n",
    "        print('Fetch batch #%d from validation dataset:' % (i+1))\n",
    "        images, labels = sess.run(['next_element:0', 'next_element:1'])\n",
    "        print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using the Dataset API to train a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "n_epochs = 15\n",
    "n_iter = n_epochs * (len(train_paths) // BATCH_SIZE)\n",
    "\n",
    "# Architecture\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256\n",
    "height, width = 28, 28\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\AdvanceIDE\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow_core\\python\\data\\util\\random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    \n",
    "    tf.set_random_seed(123)\n",
    "\n",
    "    # Input data\n",
    "    next_element = datareader()\n",
    "    \n",
    "    tf_images = tf.placeholder_with_default(next_element[0],\n",
    "                                            shape=[None, 28, 28, 1], \n",
    "                                            name='images')\n",
    "    tf_labels = tf.placeholder_with_default(next_element[1], \n",
    "                                            shape=[None, 10], \n",
    "                                            name='labels')\n",
    "    \n",
    "    tf_images = tf.reshape(tf_images, (tf.shape(tf_images)[0], 784))\n",
    "    tf_images = tf.cast(tf_images, dtype=tf.float32)\n",
    "\n",
    "    # Model parameters\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.truncated_normal([height*width, n_hidden_1], stddev=0.1)),\n",
    "        'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2], stddev=0.1)),\n",
    "        'out': tf.Variable(tf.truncated_normal([n_hidden_2, n_classes], stddev=0.1))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "        'b2': tf.Variable(tf.zeros([n_hidden_2])),\n",
    "        'out': tf.Variable(tf.zeros([n_classes]))\n",
    "    }\n",
    "\n",
    "    # Multilayer perceptron\n",
    "    layer_1 = tf.add(tf.matmul(tf_images, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "\n",
    "    # Loss and optimizer\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=out_layer, labels=tf_labels)\n",
    "    cost = tf.reduce_mean(loss, name='cost')\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train = optimizer.minimize(cost, name='train')\n",
    "\n",
    "    # Prediction\n",
    "    prediction = tf.argmax(out_layer, 1, name='prediction')\n",
    "    correct_prediction = tf.equal(tf.argmax(tf_labels, 1), tf.argmax(out_layer, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | AvgCost: 0.007\n",
      "Epoch: 002 | AvgCost: 0.472\n",
      "Epoch: 003 | AvgCost: 0.234\n",
      "Epoch: 004 | AvgCost: 0.180\n",
      "Epoch: 005 | AvgCost: 0.148\n",
      "Epoch: 006 | AvgCost: 0.126\n",
      "Epoch: 007 | AvgCost: 0.109\n",
      "Epoch: 008 | AvgCost: 0.095\n",
      "Epoch: 009 | AvgCost: 0.084\n",
      "Epoch: 010 | AvgCost: 0.075\n",
      "Epoch: 011 | AvgCost: 0.067\n",
      "Epoch: 012 | AvgCost: 0.060\n",
      "Epoch: 013 | AvgCost: 0.055\n",
      "Epoch: 014 | AvgCost: 0.049\n",
      "Epoch: 015 | AvgCost: 0.045\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run('train_iter_init')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver0 = tf.train.Saver()\n",
    "    \n",
    "    avg_cost = 0.\n",
    "    iter_per_epoch = n_iter // n_epochs\n",
    "    epoch = 0\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        \n",
    "        _, cost = sess.run(['train', 'cost:0'])\n",
    "        avg_cost += cost\n",
    "        \n",
    "        if not i % iter_per_epoch:\n",
    "            epoch += 1\n",
    "            avg_cost /= iter_per_epoch\n",
    "            print(\"Epoch: %03d | AvgCost: %.3f\" % (epoch, avg_cost))\n",
    "            avg_cost = 0.\n",
    "            sess.run('train_iter_init')\n",
    "    \n",
    "    saver0.save(sess, save_path='./mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | AvgCost: 0.007\n",
      "Epoch: 002 | AvgCost: 0.472\n",
      "Epoch: 003 | AvgCost: 0.234\n",
      "Epoch: 004 | AvgCost: 0.180\n",
      "Epoch: 005 | AvgCost: 0.148\n",
      "Epoch: 006 | AvgCost: 0.126\n",
      "Epoch: 007 | AvgCost: 0.109\n",
      "Epoch: 008 | AvgCost: 0.095\n",
      "Epoch: 009 | AvgCost: 0.084\n",
      "Epoch: 010 | AvgCost: 0.075\n",
      "Epoch: 011 | AvgCost: 0.067\n",
      "Epoch: 012 | AvgCost: 0.060\n",
      "Epoch: 013 | AvgCost: 0.055\n",
      "Epoch: 014 | AvgCost: 0.049\n",
      "Epoch: 015 | AvgCost: 0.045\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run('train_iter_init')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver0 = tf.train.Saver()\n",
    "    \n",
    "    avg_cost = 0.\n",
    "    iter_per_epoch = n_iter // n_epochs\n",
    "    epoch = 0\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        \n",
    "        _, cost = sess.run(['train', 'cost:0'])\n",
    "        avg_cost += cost\n",
    "        \n",
    "        if not i % iter_per_epoch:\n",
    "            epoch += 1\n",
    "            avg_cost /= iter_per_epoch\n",
    "            print(\"Epoch: %03d | AvgCost: %.3f\" % (epoch, avg_cost))\n",
    "            avg_cost = 0.\n",
    "            sess.run('train_iter_init')\n",
    "    \n",
    "    saver0.save(sess, save_path='./mlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feeding new datapoints through placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mlp\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-f8f1de86ca0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mnum_correct\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlab\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_correct\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy: %.1f%%'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "\n",
    "img_paths = np.array([p for p in glob.iglob('mnist_test/*/*.jpg')])\n",
    "labels = np.array([int(path.split('/')[1]) for path in img_paths])\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver1 = tf.train.import_meta_graph('./mlp.meta')\n",
    "    saver1.restore(sess, save_path='./mlp')\n",
    "    \n",
    "    num_correct = 0\n",
    "    cnt = 0\n",
    "    for path, lab in zip(img_paths, labels):\n",
    "        cnt += 1\n",
    "        image = mpimg.imread(path)\n",
    "        image = image.reshape(1, 28, 28, 1)\n",
    "        \n",
    "        pred = sess.run('prediction:0', \n",
    "                         feed_dict={'images:0': image})\n",
    "\n",
    "        num_correct += int(lab == pred[0])\n",
    "    acc = num_correct / cnt * 100\n",
    "\n",
    "print('Test accuracy: %.1f%%' % acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
