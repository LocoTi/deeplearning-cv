{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Input Pipelines to Read Data from TFRecords Files\n",
    "\n",
    "TensorFlow provides users with multiple options for providing data to the model. One of the probably most common methods is to define placeholders in the TensorFlow graph and feed the data from the current Python session into the TensorFlow Session using the feed_dict parameter. Using this approach, a large dataset that does not fit into memory is most conveniently and efficiently stored using NumPy archives as explained in [Chunking an Image Dataset for Minibatch Training using NumPy NPZ Archives](https://render.githubusercontent.com/view/image-data-chunking-npz.ipynb) or HDF5 data base files ([Storing an Image Dataset for Minibatch Training using HDF5](https://render.githubusercontent.com/view/image-data-chunking-hdf5.ipynb)).\n",
    "\n",
    "Another approach, which is often preferred when it comes to computational efficiency, is to do the \"data loading\" directly in the graph using input queues from so-called TFRecords files, which will be illustrated in this notebook.\n",
    "\n",
    "Beyond the examples in this notebook, you are encouraged to read more in TensorFlow's \"[Reading Data](https://www.tensorflow.org/programmers_guide/reading_data)\" guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from helper import mnist_export_to_jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 123\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "mnist_path = \"D:/work/data/Python/tensorflow/mnist/data/\"\n",
    "mnist_export_to_jpg(path=mnist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for i in ('train', 'valid', 'test'):\n",
    "    print('mnist_%s subdirectories' % i, os.listdir(os.path.join(mnist_path, 'mnist_%s' % i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "mnist_train_path = os.path.join(mnist_path, 'mnist_train/9/')\n",
    "some_img = os.path.join(mnist_train_path, os.listdir(mnist_train_path)[0])\n",
    "\n",
    "img = mpimg.imread(some_img)\n",
    "print(img.shape)\n",
    "plt.imshow(img, cmap='binary');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Saving images as TFRecords files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_tfrecords(data_stempath,\n",
    "                        shuffle=False, \n",
    "                        random_seed=None):\n",
    "    \n",
    "    def int64_to_feature(value):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "    \n",
    "    for s in ['train', 'valid', 'test']:\n",
    "\n",
    "        with tf.python_io.TFRecordWriter('mnist_%s.tfrecords' % s) as writer:\n",
    "\n",
    "            img_paths = np.array([p for p in glob.iglob('%s/**/*.jpg' % \n",
    "                                  os.path.join(data_stempath, \"mnist_\" + s), \n",
    "                                   recursive=True)])\n",
    "            \n",
    "            print(img_paths.shape)\n",
    "            print(img_paths[0])\n",
    "            if shuffle:\n",
    "                rng = np.random.RandomState(random_seed)\n",
    "                rng.shuffle(img_paths)\n",
    "\n",
    "            for idx, path in enumerate(img_paths):\n",
    "                label = int(os.path.basename(os.path.dirname(path)))\n",
    "                image = mpimg.imread(path)\n",
    "                image = image.reshape(-1).tolist()\n",
    "\n",
    "                if (idx + 1) % 10000 == 0:\n",
    "                    print(\"dealing mnist_{}, idx: {}\".format(s, (idx+1)))\n",
    "                \n",
    "                \n",
    "                example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                    'image': int64_to_feature(image),\n",
    "                    'label': int64_to_feature([label])}))\n",
    "\n",
    "                writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_tfrecords(data_stempath=mnist_path, shuffle=True, random_seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure that the images were serialized correctly, let us load an image back from TFRecords using the [`tf.python_io.tf_record_iterator`](https://www.tensorflow.org/api_docs/python/tf/python_io/tf_record_iterator) and display it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "record_iterator = tf.python_io.tf_record_iterator(path='mnist_train.tfrecords')\n",
    "\n",
    "for r in record_iterator:\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(r)\n",
    "    \n",
    "    label = example.features.feature['label'].int64_list.value[0]\n",
    "    print('Label:', label)\n",
    "    img = np.array(example.features.feature['image'].int64_list.value)\n",
    "    img = img.reshape((28, 28))\n",
    "    plt.imshow(img, cmap='binary')\n",
    "    plt.show\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading images via the TFRecordReader\n",
    "\n",
    "\n",
    "Roughly speaking, we can regard the TFRecordReader as a class that let's us load images \"symbolically\" inside a TensorFlow graph. A TFRecordReader uses the state in the graph to remember the location of a .tfrecord file that it reads and lets us iterate over training examples and batches after initializing the graph as we will see later.\n",
    "\n",
    "To see how it works, let's start with a simple function that reads one image at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_one_image(tfrecords_queue, normalize=True):\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    key, value = reader.read(tfrecords_queue)\n",
    "    features = tf.parse_single_example(value,\n",
    "        features={'label': tf.FixedLenFeature([], tf.int64),\n",
    "                  'image': tf.FixedLenFeature([784], tf.int64)})\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    image = tf.cast(features['image'], tf.float32)\n",
    "    onehot_label = tf.one_hot(indices=label, depth=10)\n",
    "    \n",
    "    if normalize:\n",
    "        # normalize to [0, 1] range\n",
    "        image = image / 255.\n",
    "    \n",
    "    return onehot_label, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    \n",
    "    queue = tf.train.string_input_producer(['mnist_train.tfrecords'], \n",
    "                                           num_epochs=10)\n",
    "    label, image = read_one_image(queue)\n",
    "\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "   \n",
    "    for i in range(10):\n",
    "        one_label, one_image = sess.run([label, image])\n",
    "        \n",
    "    print('Label:', one_label, '\\nImage dimensions:', one_image.shape)\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    \n",
    "    queue = tf.train.string_input_producer(['mnist_train.tfrecords'], \n",
    "                                           num_epochs=10)\n",
    "    label, image = read_one_image(queue)\n",
    "    \n",
    "    \n",
    "    label_batch, image_batch = tf.train.shuffle_batch([label, image], \n",
    "                                                       batch_size=64,\n",
    "                                                       capacity=5000,\n",
    "                                                       min_after_dequeue=2000,\n",
    "                                                       num_threads=8,\n",
    "                                                       seed=123)\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "   \n",
    "    for i in range(10):\n",
    "        many_labels, many_images = sess.run([label_batch, image_batch])\n",
    "        \n",
    "    print('Batch size:', many_labels.shape[0])\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use queue runners to train a neural network\n",
    "\n",
    "\n",
    "In this section, we will take the concepts that were introduced in the previous sections and train a multilayer perceptron from the 'mnist_train.tfrecords' file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "batch_size = 128\n",
    "n_epochs = 15\n",
    "n_iter = n_epochs * (45000 // batch_size)\n",
    "\n",
    "# Architecture\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256\n",
    "height, width = 28, 28\n",
    "n_classes = 10\n",
    "\n",
    "\n",
    "\n",
    "##########################\n",
    "### GRAPH DEFINITION\n",
    "##########################\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    \n",
    "    tf.set_random_seed(123)\n",
    "\n",
    "    # Input data\n",
    "    queue = tf.train.string_input_producer(['mnist_train.tfrecords'], \n",
    "                                           num_epochs=None)\n",
    "    label, image = read_one_image(queue)\n",
    "    \n",
    "    label_batch, image_batch = tf.train.shuffle_batch([label, image], \n",
    "                                                       batch_size=batch_size,\n",
    "                                                       seed=123,\n",
    "                                                       num_threads=8,\n",
    "                                                       capacity=5000,\n",
    "                                                       min_after_dequeue=2000)\n",
    "    \n",
    "    tf_images = tf.placeholder_with_default(image_batch,\n",
    "                                            shape=[None, 784], \n",
    "                                            name='images')\n",
    "    tf_labels = tf.placeholder_with_default(label_batch, \n",
    "                                            shape=[None, 10], \n",
    "                                            name='labels')\n",
    "\n",
    "    # Model parameters\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.truncated_normal([height*width, n_hidden_1], stddev=0.1)),\n",
    "        'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2], stddev=0.1)),\n",
    "        'out': tf.Variable(tf.truncated_normal([n_hidden_2, n_classes], stddev=0.1))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "        'b2': tf.Variable(tf.zeros([n_hidden_2])),\n",
    "        'out': tf.Variable(tf.zeros([n_classes]))\n",
    "    }\n",
    "\n",
    "    # Multilayer perceptron\n",
    "    layer_1 = tf.add(tf.matmul(tf_images, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "\n",
    "    # Loss and optimizer\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=out_layer, labels=tf_labels)\n",
    "    cost = tf.reduce_mean(loss, name='cost')\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train = optimizer.minimize(cost, name='train')\n",
    "\n",
    "    # Prediction\n",
    "    prediction = tf.argmax(out_layer, 1, name='prediction')\n",
    "    correct_prediction = tf.equal(tf.argmax(label_batch, 1), tf.argmax(out_layer, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "    \n",
    "    \n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver0 = tf.train.Saver()\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    avg_cost = 0.\n",
    "    iter_per_epoch = n_iter // n_epochs\n",
    "    epoch = 0\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        _, cost = sess.run(['train', 'cost:0'])\n",
    "        avg_cost += cost\n",
    "        \n",
    "        if not i % iter_per_epoch:\n",
    "            epoch += 1\n",
    "            avg_cost /= iter_per_epoch\n",
    "            print(\"Epoch: %03d | AvgCost: %.3f\" % (epoch, avg_cost))\n",
    "            avg_cost = 0.\n",
    "            \n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "    saver0.save(sess, save_path='./mlp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
